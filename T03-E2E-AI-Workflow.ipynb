{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbf2d92-815e-4a2e-b468-26f71cd8dbe3",
   "metadata": {},
   "source": [
    "# DEEPX Tutorial 03 - AI Porject Workflow with DEEPX NPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3b426-7d6e-4844-bf75-737a94d1055f",
   "metadata": {},
   "source": [
    "This third tutorial demonstrates the full end-to-end workflow for AI model deployment on DEEPX hardware.\n",
    "\n",
    "We will train a forklift and worker detection model, utilize the DX-COM tool for conversion to the DXNN format, and execute the final AI application on a DEEPX NPU. This process will provide a comprehensive picture of the DEEPX NPU development pipeline. \n",
    "\n",
    "This tutorial is based on dx-all-suite v2.0.0, released in September 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ad29e-2955-4f2e-beac-2e2a34bbe81f",
   "metadata": {},
   "source": [
    "## Hands-on Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c1d96-a612-4246-af9c-ebf798355fba",
   "metadata": {},
   "source": [
    "- **Detection classes**: Forklift, Worker\n",
    "- **Base AI model**: YOLOv7\n",
    "- **Dataset**: 1448 images about Forklift & Worker from [kaggle](https://www.kaggle.com/datasets/hakantaskiner/personforklift-dataset/data)\n",
    "- **Train**: Need NVIDIA GPU with more than 24G GRAM\n",
    "- **Inference NPU**: `DX-M1`\n",
    "- **AI application**: Modify and reuse the yolo demo of the DX-APP\n",
    "- **Expected output**:\n",
    "  ![img](assets/detection-goal.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8217ad7-fc19-421b-967d-98ff2dfbc762",
   "metadata": {},
   "source": [
    "## AI Workflow Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d81f9-0699-45e6-ba37-e27a481ad370",
   "metadata": {},
   "source": [
    "This diagram explains the common workflow of an AI project.\n",
    "\n",
    "We define the goal, collect and label data, and train the model.\n",
    "DX-Compiler helps make the model faster and lighter (INT8) for DX NPU.\n",
    "The final step is deploying the model to the DEEPX NPU using DX-App or DX-Stream.\n",
    "\n",
    "Each step builds toward real-world AI solutions, such as worker and forklift detection.\n",
    "![img](assets/workflow2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e8f9d-0115-48d7-a02a-1b64c84c3b72",
   "metadata": {},
   "source": [
    "## 1. AI Workflow - Model Selection based on the use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa66140-dbee-4bf2-a9ce-82f4316a8512",
   "metadata": {},
   "source": [
    "To start an AI project, we need to select an AI model that fits the use case.\n",
    "\n",
    "In this tutorial, our goal is to detect forklifts and workers.\n",
    "We will use YOLOv7, a well-known model for object detection.\n",
    "\n",
    "- Choose YOLOv7 to detect Forklift & Worker\n",
    "- For more details of YOLOv7: 👉 [link](https://docs.ultralytics.com/models/yolov7/)\n",
    "- How to use YOLOv7: 👉 [link](https://github.com/WongKinYiu/yolov7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81b7c5-ec05-412b-bc79-338f77d02b18",
   "metadata": {},
   "source": [
    "## 2. AI Workflow - Data Preparation & Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53d3cc-8142-4d59-ac44-fb7f2f836e74",
   "metadata": {},
   "source": [
    "Download the forklift-person labeled dataset from Kaggle:\n",
    " - Reference: [kaggle link](https://www.kaggle.com/datasets/hakantaskiner/personforklift-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071e952-82bb-4cf9-8c88-6a007b150d3b",
   "metadata": {},
   "source": [
    "## 3. AI Workflow - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd31d3c-e849-49d3-b7f4-10efefca0861",
   "metadata": {},
   "source": [
    "To train the model efficiently, you should use a GPU that has 24GB or more graphic memory.\n",
    "\n",
    " - How to train YOLOv7: 👉 [Link](https://colab.research.google.com/drive/1dAdjJuhXqFM_Qcd0QqAn7_AGx7abA5aX?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd943a-796f-4aec-8341-a524c71c4e2f",
   "metadata": {},
   "source": [
    "## 4. AI Workflow - Optimization with DX-Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cb05a-ee64-4392-9a09-3b0577e34a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to \"dx-tutorials/dx-all-suite/dx-compiler/dx_com\"\n",
    "import os\n",
    "root_path = os.environ.get('ROOT_PATH')\n",
    "%cd $root_path/dx-all-suite/dx-compiler/dx_com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347d2b0-3fd8-4a96-bc0e-84c5885586eb",
   "metadata": {},
   "source": [
    "Let's try to compile your pre-trained AI model to DXNN format.\n",
    "\n",
    "Overall processes are:\n",
    "1. Get a pre-trained mode on pytorch framework\n",
    "2. Convert it to ONNX format\n",
    "3. Compile ONNX to DXNN (for more details of DX-COM, refer to the user guide 👉  [here](https://developer.deepx.ai/?files=MjUxNQ==))\n",
    "\n",
    "![img](assets/dx-com-workflow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca7205-5cef-453c-863a-794925e61820",
   "metadata": {},
   "source": [
    "The source structure of DX-COM is organized as follows:\n",
    "```bash\n",
    "dx_com\n",
    " ├── calibration_dataset   # Dataset used to optimize model accuracy <br>\n",
    " ├── dx_com\n",
    " │ ├── cv2/                # Third party shared libraries (e.g., OpenCV) <br>\n",
    " │ ├── google/             # Third party shared libraries (e.g., protobuf) <br>\n",
    " │ ├── numpy/              # Third party shared libraries (e.g., NumPy) <br>\n",
    " │ ├── ...                 # Other dependencies <br>\n",
    " │ └── dx_com              # Core compiler implementation <br>\n",
    " ├── sample\n",
    " │ ├── MobilenetV1.json    # Sample configuration file <br>\n",
    " │ └── MobilenetV1.onnx    # Sample ONNX model\n",
    " └── Makefile              # Build script for compiling the sample model <br>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93624034-2283-4052-b98d-2abf9d0fb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 1\n",
    "!tree sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6655c5ab-7718-4a75-a305-54516a723d1d",
   "metadata": {},
   "source": [
    "### 4.1 Download exported ONNX file & JSON file for YOLOv7 DX-COM config from DX modelzoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2886542-8a78-4e17-801b-121deb3b41e0",
   "metadata": {},
   "source": [
    "- Download exported ONNX file: 👉 [ONNX](https://drive.google.com/file/d/1ZlRppHtz26X1ID8BUHuFMH6EVfPzDOsh/view?usp=sharing)\n",
    "- Download json file for YOLOv7 from DEEPX model zoo: Object Detection >> YOLOV7-2 >> JSON download 👉 [modelzoo](assets/modelzoo.html)\n",
    "  \n",
    "  `Note`: DX modelzoo is a list of AI models that have been verified by DEEPX and are publicly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41615afe-eb68-4e6c-a126-5b8f1c2c8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the downloaded files to the currect path\n",
    "!mv ~/Downloads/yolov7-forklift-person.onnx ./\n",
    "!mv ~/Downloads/YOLOV7-2.json ./yolov7-forklift-person.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb10634-544d-4ace-ba8a-0fd870fbf87e",
   "metadata": {},
   "source": [
    "### 4.2 Modify YOLOv7 json file for your custom env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff16168-8432-40cd-aa76-09e0fe327db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the original json file downloaded from DX model zoo\n",
    "!cat yolov7-forklift-person.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff48f4-793d-4706-9f41-a4a5febc2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'yolov7-forklift-person.json'\n",
    "\n",
    "# 1. Read JSON file\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Find and replace dictionary values by key\n",
    "data['default_loader']['dataset_path'] = \"./calibration_dataset\"\n",
    "\n",
    "# 3. Save the revised json file\n",
    "with open(file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"'{file_name}' update done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b44e9e-20ad-4a1a-be68-321b3e981ec2",
   "metadata": {},
   "source": [
    "### 4.3 Compile ONNX to DXNN by referencing json coinfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d048de7-27e3-4f22-ba11-ab63b8f03293",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./dx_com/dx_com -h\n",
    "\n",
    "# The following compile command will take more than 10 mins depending on your system performance\n",
    "#!./dx_com/dx_com -m  yolov7-forklift-person.onnx -c yolov7-forklift-person.json -o output\n",
    "\n",
    "# Move the compiled dxnn file to the dx_app path\n",
    "#!mv output/yolov7-forklift-person.dxnn $ROOT_PATH/dx-all-suite/dx-runtime/dx_app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf1b20-9182-4a77-82d0-8188d9c6e257",
   "metadata": {},
   "source": [
    "## 5. AI Workflow - Deployment on DEEPX NPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1434f2-0685-4419-b7e1-ec71b40b493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to \"dx-tutorials/dx-all-suite/dx-runtime/dx_app\"\n",
    "import os\n",
    "root_path = os.environ.get('ROOT_PATH')\n",
    "%cd $root_path/dx-all-suite/dx-runtime/dx_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0081cd6-5c86-45f2-8002-b214957be702",
   "metadata": {},
   "source": [
    "### 5.1 (Optional) If you want to skip compile process, just download complied DXNN file from the following link:\n",
    "- 👉 [DXNN](https://drive.google.com/file/d/1e9PEJeS2ZM16Y-5U2HrG9o5jzdvEaIh0/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c51947-4547-42de-82c7-f6996195c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move it to the currect path\n",
    "!mv ~/Downloads/yolov7-forklift-person.dxnn ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54f93a-31ff-4f9c-8fd5-1de4776cc622",
   "metadata": {},
   "source": [
    "### 5.2 Modify the yolo app of DX-APP for your customized model (Forklift & Worker detection model)\n",
    "- Change the class number from 80 to 2\n",
    "- Change the class list for Forklist & Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207639f-ba02-436a-b30d-bf2768762452",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFF_TEXT = r\"\"\"\n",
    "diff --git a/demos/demo_utils/yolo_cfg.cpp b/demos/demo_utils/yolo_cfg.cpp\n",
    "index 7866d70..cd8f49d 100644\n",
    "--- a/demos/demo_utils/yolo_cfg.cpp\n",
    "+++ b/demos/demo_utils/yolo_cfg.cpp\n",
    "@@ -144,14 +144,14 @@ YoloParam yolov7_640 = {\n",
    "     0.3,\n",
    "     0.4,\n",
    "     0,\n",
    "-    80,\n",
    "+    2,\n",
    "     \"output\",\n",
    "     {\n",
    "         createYoloLayerParam(\"onnx::Reshape_491\", 80, 80, 3, { 12.0, 19.0, 40.0 }, { 16.0, 36.0, 28.0 }, { 0 }),\n",
    "         createYoloLayerParam(\"onnx::Reshape_525\", 40, 40, 3, { 36.0, 76.0, 72.0 }, { 75.0, 55.0, 146.0 }, { 1 }),\n",
    "         createYoloLayerParam(\"onnx::Reshape_559\", 20, 20, 3, { 142.0, 192.0, 459.0 }, { 110.0, 243.0, 401.0 }, { 2 })\n",
    "     },\n",
    "-    { \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"trafficlight\", \"firehydrant\", \"stopsign\", \"parkingmeter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sportsball\", \"kite\", \"baseballbat\", \"baseballglove\", \"skateboard\", \"surfboard\", \"tennisracket\", \"bottle\", \"wineglass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hotdog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cellphone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddybear\", \"hairdrier\", \"toothbrush\"},\n",
    "+    { \"Forklift\", \"Worker\" },\n",
    "     PostProcType::OD\n",
    " };\n",
    " \n",
    "@@ -241,4 +241,4 @@ YoloParam yolov5s_face_640 = {\n",
    "     },\n",
    "     {\"face\"},\n",
    "     PostProcType::FACE\n",
    "-};\n",
    "\\ No newline at end of file\n",
    "+};\n",
    "\"\"\"\n",
    "\n",
    "# 파일로 저장\n",
    "with open(\"dx_app_update.diff\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(DIFF_TEXT)\n",
    "\n",
    "print(\"Saved: dx_app_update.diff (bytes)\", len(DIFF_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8598424-1ee1-4413-9ecd-ab7f6fd6e2d6",
   "metadata": {},
   "source": [
    "Apply the modified code by using git apply command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553917b-c2f9-425b-8184-7c4c3a92a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git apply dx_app_update.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba0bdd-1df3-47d2-a454-a1bc39c8768c",
   "metadata": {},
   "source": [
    "### 5.3 Rebuild the DX-APP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49755c1-7ec1-425a-8748-c50b216e83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef5fbb5-57c5-425b-bb18-be6c09f84008",
   "metadata": {},
   "source": [
    "### 5.4 Run the revised DX-APP yolo app with your custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b651f-e0d3-476c-a750-71f28e63ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/yolo -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0532a-9af2-4002-9423-c2ea6f670b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $ROOT_PATH/assets/forklift-worker.png ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f0a12-2d2c-4a0b-8fb9-167f9e3ff186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/yolo -m yolov7-forklift-person.dxnn -i forklift-worker.png -p 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d86bb5-c77a-4144-8072-4c30ac0e0386",
   "metadata": {},
   "source": [
    "### 5.5 Show the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad103e-61d5-467a-8e29-f8e3af4c2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Show the image\n",
    "display(Image(filename=\"result.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
