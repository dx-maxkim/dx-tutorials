{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88efc8e-edb8-4f01-bcdf-dffc19f2533a",
   "metadata": {},
   "source": [
    "# DEEPX Tutorial 04 - DX STREAM workflow\n",
    "\n",
    "This forth tutorial intruduces DX-STREAM overview and end-to-end workflow for a custom AI model with DX-STREAM.\n",
    "\n",
    " - Understand what DX-STREAM is and where it fits in the DEEPX SDK\n",
    " - Learn the core elements (DxPreprocess → DxInfer → DxPostprocess → DxTracker → DxOsd)\n",
    " - Implement custom preprocess/postprocess libraries to support customized AI models\n",
    "\n",
    ">This tutorial is based on dx-all-suite v2.0.0, released in September 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b657a27-5033-462a-a1fd-5e3c2dc41038",
   "metadata": {},
   "source": [
    "## DX-STREAM Overview\n",
    "A set of GStreamer elements for Vision AI on DEEPX NPUs.\n",
    "```text\n",
    "Source → (decodebin) → DxPreprocess → DxInfer → DxPostprocess → DxTracker → DxOsd → Sink\n",
    "```\n",
    "- **DxPreprocess**: resize/ROI/color space, optional custom library\n",
    "- **DxInfer**: (Inference) runs .dxnn model, links to preprocess via `preprocess-id`\n",
    "- **DxPostprocess**: decode tensors → metadata, optional custom library\n",
    "- **DxTracker**: assign stable IDs (e.g., OC_SORT)\n",
    "- **DxOsd**: (On-Screen Display) draw boxes/labels/poses/segmentation onto frames\n",
    "\n",
    "  ![img](assets/dx-stream-pipeline.png)\n",
    "\n",
    "For more details, download DX_STREAM User Guide from 👉 [here](https://developer.deepx.ai/?files=MjUxNw==)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfffb69-ea1d-4b7b-bc95-4bc2881a6493",
   "metadata": {},
   "source": [
    "## Prerequisites:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0036c6-b9d5-4efd-90c9-be411294f7d4",
   "metadata": {},
   "source": [
    "1. Move to `dx_stream` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f641d-f931-4363-ba8e-0e75927620a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to \"dx-tutorials/dx-all-suite/dx-runtime/dx_stream\"\n",
    "import os\n",
    "root_path = os.environ.get('ROOT_PATH')\n",
    "%cd $root_path/dx-all-suite/dx-runtime/dx_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3026b6-839f-4cb5-8312-91f2a829ae42",
   "metadata": {},
   "source": [
    "2. Download required models and sample videos by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15b670-4f56-4375-8f65-b39e5d59fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assets (models + videos) are downloaded and placed in the assets/ directory.\n",
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b9fdd-52ce-461e-ba79-afa9ab120419",
   "metadata": {},
   "source": [
    "3. Verify required plugins - following dx-plugins should be displayed:\n",
    "  - dxgather: DxGather\n",
    "  - dxinfer: DXInfer\n",
    "  - dxinputselector: DXInputSelector\n",
    "  - dxmsgbroker: DXMsgBroker\n",
    "  - dxmsgconv: DXMsgConv\n",
    "  - dxosd: DXOsd\n",
    "  - dxoutputselector: DXOutputSelector\n",
    "  - dxpostprocess: DXPostprocess\n",
    "  - dxpreprocess: DXPreprocess\n",
    "  - dxrate: DXRate\n",
    "  - dxtracker: DXTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe16065-10b4-48a3-8cad-f59a063e2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gst-inspect-1.0 dxstream || echo 'dxstream plugin not found'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c9d96-890c-4e8b-af0b-dcf0332d324a",
   "metadata": {},
   "source": [
    "## Quick Starts with run_demo scripts in DX_STREAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c525661-2ffc-49f9-96c0-6726962802eb",
   "metadata": {},
   "source": [
    "1. Let's run the YOLOv7 pipeline with video input:\n",
    "   - `Note`: You can stop the pipeline by clicking the stop button ('■') above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306a3e6-b27b-47d1-acfd-615894f8b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video file as an input\n",
    "VIDEO_SRC='dx_stream/samples/videos/doughnut.mp4'\n",
    "\n",
    "# GStreamer pipeline configuration\n",
    "!gst-launch-1.0 filesrc location=$VIDEO_SRC ! decodebin ! \\\n",
    "                   dxpreprocess config-file-path=dx_stream/configs/Object_Detection/YoloV7/preprocess_config.json ! queue ! \\\n",
    "                   dxinfer config-file-path=dx_stream/configs/Object_Detection/YoloV7/inference_config.json ! queue ! \\\n",
    "                   dxpostprocess config-file-path=dx_stream/configs/Object_Detection/YoloV7/postprocess_config.json ! queue ! \\\n",
    "                   dxosd width=1280 height=720 ! queue ! \\\n",
    "                   videoconvert ! fpsdisplaysink sync=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3521c-bc02-4423-8010-ca73dbdbb367",
   "metadata": {},
   "source": [
    "2. Let's learn about the definition and usage of each plugin using **gst-inspect-1.0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f6a38-0449-4cd1-b01f-64c068d5af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dxpreprocess plugin\n",
    "!gst-inspect-1.0 dxpreprocess\n",
    "!echo \"==============[ Configuration Start ]==============\"\n",
    "!cat dx_stream/configs/Object_Detection/YoloV7/preprocess_config.json\n",
    "!echo \"==============[  Configuration End  ]==============\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842df0d0-e7de-45fb-8ba7-4f5006bc0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dxinfer plugin\n",
    "!gst-inspect-1.0 dxinfer\n",
    "!echo \"==============[ Configuration Start ]==============\"\n",
    "!cat dx_stream/configs/Object_Detection/YoloV7/inference_config.json\n",
    "!echo \"==============[  Configuration End  ]==============\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5928ed-ed35-4d3e-a07d-cefe7e866a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dxpostprocess plugin\n",
    "!gst-inspect-1.0 dxpostprocess\n",
    "!echo \"==============[ Configuration Start ]==============\"\n",
    "!cat dx_stream/configs/Object_Detection/YoloV7/postprocess_config.json\n",
    "!echo \"==============[  Configuration End  ]==============\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3ddf6-7c05-4f82-822b-84b4bd755494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dxosd plugin\n",
    "!gst-inspect-1.0 dxosd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac29565-bf58-49b1-af77-7e971086f498",
   "metadata": {},
   "source": [
    "## Run Demo Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be5fb3-7c6a-47ae-aade-a4b5eed78acc",
   "metadata": {},
   "source": [
    "There is a **`run_demo.sh`** script file in the dx_stream path, which contains main examples of using dx_stream.\n",
    "\n",
    "This script calls the following script based on the user's selection (from 0 to 7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565573f0-eb7e-4d0e-a2d0-f14b1fd415a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the demo list - Total 8 GStreamer demos\n",
    "!tail -n 15 run_demo.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ff311-35d2-4644-9e18-fa2b3e3fea1c",
   "metadata": {},
   "source": [
    "Let's run each demo by changing the argument from '0' to '7':\n",
    "   - `Note`: You can stop the pipeline by clicking the stop button ('■') above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea4b09-a02a-4604-b015-f21031893723",
   "metadata": {},
   "source": [
    "![img](assets/pipline-single-detection.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96b0aa-f55a-4ee6-8403-4d50a16ecead",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 0 # single_network/object_detectionS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11514b9b-ae99-4d23-9332-81fe13a824aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 1 # single_network/face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4eee5-d92a-437e-8fe0-c84cb255b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 3 # single_network/pose_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11ec9b-08c1-4cf7-9005-7d478b9eb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 4 # single_network/semantic_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbecfb-314b-413a-a678-df2d4dba8a54",
   "metadata": {},
   "source": [
    "![img](assets/pipline-single-tracking.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d060e-01f7-4299-806f-1c1d23f7a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 2 # tracking/run_YOLOV5S_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a215d-febf-4e10-8799-3f50487645e0",
   "metadata": {},
   "source": [
    "![img](assets/pipeline-multi-stream.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd097649-57dd-48e4-8253-63eb3a9c481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 5 # multi_stream/run_multi_stream_YOLOV5S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b98cb-cca6-456f-a374-558c5d59917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 6 # rtsp/run_RTSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9a875-da1b-4fd5-994b-d186481f1420",
   "metadata": {},
   "source": [
    "![img](assets/pipeline-secondary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7ff49-89f2-497f-a96a-db12cb76e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_demo.sh <<< 7 # secondary_mode/run_secondary_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db699b59-2692-49a1-b115-59a8e8120630",
   "metadata": {},
   "source": [
    "## Writeing Your Own Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472086d-3ecd-4ed8-adb0-33b58a7dc7d8",
   "metadata": {},
   "source": [
    "This chapter describes how to integrate a custom AI model and implement user-defined logic within the\n",
    "DX-STREAM pipeline.\n",
    "\n",
    "This guide focuses on how to configure and integrate custom logic into the DX-STREAM pipeline using\n",
    "modular elements such as DxPreprocess, DxInfer, and DxPostprocess.\n",
    "\n",
    "We will reuse the custom model (Forklift & Worker detector) in the previous tutorial-03. Therefore, need to customize the dxpostporcess plugin.\n",
    "\n",
    "![img](assets/custom-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc17e78-b854-40ea-b591-ab907be1ae69",
   "metadata": {},
   "source": [
    "### 1. Download complied DXNN file from the following link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ad22c-dba7-4426-bf4d-839629092c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"cs.deepx.ai/_deepx_fae_archive/dx-tutorials/yolov7-forklift-person.dxnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e09e31-46e1-4c08-821f-60b67fbe4479",
   "metadata": {},
   "source": [
    "### 2. Modify \"dx_stream/custom_library/postprocess_library/YoloV7/postprocess.cpp\" file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283cd01-b102-4993-93d2-66b8b78dda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFF_TEXT = r\"\"\"diff --git a/dx_stream/custom_library/postprocess_library/YoloV7/postprocess.cpp b/dx_stream/custom_library/postprocess_library/YoloV7/postprocess.cpp\n",
    "index 7d048e9..26125ca 100644\n",
    "--- a/dx_stream/custom_library/postprocess_library/YoloV7/postprocess.cpp\n",
    "+++ b/dx_stream/custom_library/postprocess_library/YoloV7/postprocess.cpp\n",
    "@@ -58,21 +58,11 @@ struct YoloConfig {\n",
    "     float nms_threshold = 0.4f;      // IoU threshold for NMS\n",
    "\n",
    "     // Number of classes in your dataset\n",
    "-    int num_classes = 80;\n",
    "+    int num_classes = 2;\n",
    "\n",
    "     // COCO dataset class names (modify for your dataset)\n",
    "     std::vector<std::string> class_names = {\n",
    "-        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
    "-        \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "-        \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
    "-        \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
    "-        \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n",
    "-        \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "-        \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
    "-        \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
    "-        \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\",\n",
    "-        \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "-        \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "+        \"Forklift\", \"Worker\"\n",
    "     };\n",
    " };\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 파일로 저장\n",
    "with open(\"dx_stream_update.diff\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(DIFF_TEXT)\n",
    "\n",
    "print(\"Saved: dx_stream_update.diff (bytes)\", len(DIFF_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99300027-6ba4-4730-bc26-a9ef6ceeaaca",
   "metadata": {},
   "source": [
    "### 3. Apply the modified code by using git apply command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a64b2-7220-4b34-8336-c405fec3db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git apply --whitespace=fix dx_stream_update.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03033c18-29b6-4da9-ba15-9fb95e0307ba",
   "metadata": {},
   "source": [
    "### 4. Re-build DX_STREAM libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a5a13-d73d-47e3-be6b-695f8a021931",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ../venv-dx-runtime/bin/activate && ./build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ae0eb-c0d9-475e-ac57-3e48a5fbc025",
   "metadata": {},
   "source": [
    "### 5. Create configuration json to load your custom model (yolov7-forklift-person.dxnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d834565-155b-4efd-8083-566f095298a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "yolov7_custom = {\n",
    "    \"preprocess_id\": 1,\n",
    "    \"inference_id\": 1,\n",
    "    \"model_path\" : \"./yolov7-forklift-person.dxnn\"\n",
    "}\n",
    "with open(\"yolov7-forklift-person.json\", \"w\") as f: json.dump(yolov7_custom, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e347ec-1ce8-4174-a6b8-d8f959fa4b3c",
   "metadata": {},
   "source": [
    "### 6. Copy a video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a147f-85a7-48f4-8d21-a86ab003efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../../assets/forklift-worker.mp4 ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb2736-423b-4e1e-8ca9-27f9db2653c5",
   "metadata": {},
   "source": [
    "### 7. Run the following DX-STREAM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669200a-7ac0-4a13-b5b4-cebdd5d16823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video file as an input\n",
    "VIDEO_SRC='forklift-worker.mp4'\n",
    "\n",
    "# GStreamer pipeline configuration\n",
    "!gst-launch-1.0 filesrc location=$VIDEO_SRC ! decodebin ! \\\n",
    "                   dxpreprocess config-file-path=dx_stream/configs/Object_Detection/YoloV7/preprocess_config.json ! queue ! \\\n",
    "                   dxinfer config-file-path=yolov7-forklift-person.json ! queue ! \\\n",
    "                   dxpostprocess config-file-path=dx_stream/configs/Object_Detection/YoloV7/postprocess_config.json ! queue ! \\\n",
    "                   dxosd width=1280 height=720 ! queue ! \\\n",
    "                   videoconvert ! fpsdisplaysink sync=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106bd3d-2890-4be7-a118-8865fd905772",
   "metadata": {},
   "source": [
    "## Debug Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41369033-aaf3-404a-bb25-c467174d7dad",
   "metadata": {},
   "source": [
    "Dump GSTreamer pipiline configurations as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef4240-1267-47d7-ba90-bd70f61d830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57466903-11dc-4cac-96d1-1c526e1d46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GST_DEBUG_DUMP_DOT_DIR=./ && ./run_demo.sh <<< 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a374ef-0e53-4593-b6b5-5a17467e1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dot -Tpng -o NULL_READY.png *NULL_READY.dot\n",
    "#!dot -Tpng -o READY_PAUSED.png *READY_PAUSED.dot\n",
    "!dot -Tpng -o PAUSED_PLAYING.png *PAUSED_PLAYING.dot\n",
    "#!dot -Tpng -o PLAYING_PAUSED.png *PLAYING_PAUSED.dot\n",
    "# -Tpng : output format is 'png'\n",
    "# -o : output file name\n",
    "# *.dot : input file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f5fe9-508c-4168-9df5-f1749aeeb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Show the image\n",
    "display(Image(filename=\"PAUSED_PLAYING.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c66f4-3b5e-41ac-96b6-679470210ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
