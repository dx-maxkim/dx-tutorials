{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0b7fe7",
   "metadata": {},
   "source": [
    "# DX-STREAM Tutorial 3 — Custom Model Integration\n",
    "_Last updated: 2025-10-19 22:39_\n",
    "\n",
    "### Goals\n",
    "- Swap in your own `.dxnn` model\n",
    "- Implement custom **preprocess**/**postprocess** libraries\n",
    "- Wire everything via JSON configs and run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70768d87",
   "metadata": {},
   "source": [
    "## 1) Prepare Your Model\n",
    "1. Convert **ONNX → DXNN** using DX-COM (not covered in detail here).\n",
    "2. Confirm tensor shapes with a parser (example):\n",
    "\n",
    "```bash\n",
    "parse_model -m your_model.dxnn\n",
    "```\n",
    "Record output names/shapes for your postprocess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e908b74",
   "metadata": {},
   "source": [
    "## 2) JSON Config Templates\n",
    "Below are minimal examples. Adjust to your model specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd85780",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_json = {\n",
    "  \"preprocess_id\": 1,\n",
    "  \"resize_width\": 640,\n",
    "  \"resize_height\": 640,\n",
    "  \"keep_ratio\": True,\n",
    "  \"library_file_path\": \"/usr/share/dx-stream/lib/libcustompreproc.so\",\n",
    "  \"function_name\": \"CustomPreprocessFunc\"\n",
    "}\n",
    "infer_json = {\n",
    "  \"preprocess_id\": 1,\n",
    "  \"inference_id\": 1,\n",
    "  \"model_path\": \"./models/your_model.dxnn\",\n",
    "  \"secondary_mode\": False\n",
    "}\n",
    "post_json = {\n",
    "  \"inference_id\": 1,\n",
    "  \"library_file_path\": \"/usr/share/dx-stream/lib/libpostprocess_custom.so\",\n",
    "  \"function_name\": \"Postprocess_Custom\"\n",
    "}\n",
    "from pathlib import Path\n",
    "cfg_dir = Path(\"configs\"); cfg_dir.mkdir(exist_ok=True)\n",
    "(Path(\"configs/preprocess.json\")).write_text(__import__('json').dumps(pre_json, indent=2))\n",
    "(Path(\"configs/infer.json\")).write_text(__import__('json').dumps(infer_json, indent=2))\n",
    "(Path(\"configs/postprocess.json\")).write_text(__import__('json').dumps(post_json, indent=2))\n",
    "print(\"Wrote configs to ./configs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb46943",
   "metadata": {},
   "source": [
    "## 3) Custom Preprocess (C++ Template)\n",
    "Create a minimal preprocessor that writes into the provided `input_tensor` buffer. Do **not** re-allocate or free it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e682a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "src_dir = Path(\"custom_libs\"); src_dir.mkdir(exist_ok=True)\n",
    "(Path(\"custom_libs/preprocess.cpp\")).write_text(r'''\n",
    "#include <cstring>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include \"dx_frame_meta.hpp\"  // Provided by DX-STREAM headers\n",
    "extern \"C\" void CustomPreprocessFunc(DXFrameMeta *frame_meta, DXObjectMeta *object_meta, void* input_tensor) {\n",
    "    // Example: copy a resized BGR frame into input_tensor as float32 NHWC\n",
    "    // NOTE: replace this with the correct layout/normalization for your model.\n",
    "    if(!frame_meta || !frame_meta->_buf) return;\n",
    "    // (Pseudo) fetch width/height from your config or tensor spec\n",
    "    const int W = 640, H = 640, C = 3;\n",
    "    cv::Mat src; // You would map frame_meta->_buf to cv::Mat using caps info\n",
    "    // For a template, use a dummy image (black):\n",
    "    cv::Mat resized(H, W, CV_8UC3, cv::Scalar(0,0,0));\n",
    "    // Convert to float and normalize [0,1]\n",
    "    cv::Mat f32; resized.convertTo(f32, CV_32FC3, 1.0/255.0);\n",
    "    // Copy NHWC float32 into input_tensor\n",
    "    std::memcpy(input_tensor, f32.ptr<float>(0), H*W*C*sizeof(float));\n",
    "}\n",
    "''')\n",
    "print(\"Wrote custom_libs/preprocess.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052f7e2",
   "metadata": {},
   "source": [
    "## 4) Custom Postprocess (C++ Template)\n",
    "Decode tensors to structured objects (bboxes, classes, scores) and attach to `DXFrameMeta`. For secondary-mode, modify existing `DXObjectMeta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Path(\"custom_libs/postprocess.cpp\")).write_text(r'''\n",
    "#include <vector>\n",
    "#include \"dx_post_meta.hpp\"   // Provided by DX-STREAM headers\n",
    "#include \"dx_tensor.hpp\"\n",
    "extern \"C\" void Postprocess_Custom(std::vector<dxs::DXTensor> network_output,\n",
    "                                   DXFrameMeta *frame_meta, DXObjectMeta *object_meta) {\n",
    "    // Example: create one dummy detection\n",
    "    if(!frame_meta) return;\n",
    "    DXObjectMeta det{};\n",
    "    det.rect.x = 0.1f; det.rect.y = 0.1f; det.rect.w = 0.5f; det.rect.h = 0.5f;\n",
    "    det.score = 0.99f;\n",
    "    det.class_id = 0;\n",
    "    dx_attach_object_meta(frame_meta, &det);\n",
    "}\n",
    "''')\n",
    "print(\"Wrote custom_libs/postprocess.cpp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6521262",
   "metadata": {},
   "source": [
    "## 5) Build with Meson/Ninja (Template)\n",
    "This assumes DX-STREAM headers & libs are installed system-wide (e.g., `/usr/local/include/dx_stream`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Path(\"custom_libs/meson.build\")).write_text(r'''\n",
    "project('dx_stream_custom_libs', 'cpp', version : '1.0.0', default_options: ['cpp_std=c++17'])\n",
    "\n",
    "dx_stream_dep = declare_dependency(\n",
    "  include_directories : include_directories('/usr/local/include/dx_stream'),\n",
    "  link_args : ['-L/usr/local/lib', '-lgstdxstream']\n",
    ")\n",
    "\n",
    "gst_dep = dependency('gstreamer-1.0', required : true)\n",
    "opencv_dep = dependency('opencv4', required : true)\n",
    "\n",
    "shared_library('custompreproc',\n",
    "  sources: ['preprocess.cpp'],\n",
    "  dependencies: [dx_stream_dep, gst_dep, opencv_dep],\n",
    "  install: true,\n",
    "  install_dir: '/usr/share/dx-stream/lib'\n",
    ")\n",
    "\n",
    "shared_library('postprocess_custom',\n",
    "  sources: ['postprocess.cpp'],\n",
    "  dependencies: [dx_stream_dep, gst_dep],\n",
    "  install: true,\n",
    "  install_dir: '/usr/share/dx-stream/lib'\n",
    ")\n",
    "''')\n",
    "print(\"Wrote custom_libs/meson.build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build commands (run on your system, may require sudo for install paths)\n",
    "# !sudo apt-get update && sudo apt-get install -y meson ninja-build\n",
    "# !meson setup builddir custom_libs && ninja -C builddir && sudo ninja -C builddir install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bc9c2",
   "metadata": {},
   "source": [
    "## 6) Run a Standalone Pipeline (Template)\n",
    "Example using a local MP4 and your custom configs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = r'''\n",
    "filesrc location=./video.mp4 ! decodebin ! dxpreprocess config-file-path=./configs/preprocess.json ! dxinfer config-file-path=./configs/infer.json ! dxpostprocess config-file-path=./configs/postprocess.json ! dxosd width=1280 height=720 ! videoconvert ! autovideosink sync=false\n",
    "'''.strip()\n",
    "print(pipeline)\n",
    "# To run from notebook (uncomment when ready):\n",
    "# import subprocess, shlex\n",
    "# subprocess.run(shlex.split(\"gst-launch-1.0 \"+pipeline), check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622121c",
   "metadata": {},
   "source": [
    "## 7) Add Multi-Object Tracking (Optional)\n",
    "Insert `dxtracker` after `dxpostprocess` to get stable IDs. Example config:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069912cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_cfg = {\n",
    "  \"tracker_name\": \"OC_SORT\",\n",
    "  \"params\": {\n",
    "    \"det_thresh\": 0.5,\n",
    "    \"max_age\": 30,\n",
    "    \"min_hits\": 3,\n",
    "    \"iou_threshold\": 0.3\n",
    "  }\n",
    "}\n",
    "Path(\"configs/tracker.json\").write_text(__import__('json').dumps(tracker_cfg, indent=2))\n",
    "print(\"Wrote configs/tracker.json\")\n",
    "print(\"Pipeline: add 'dxtracker config-file-path=./configs/tracker.json' before dxosd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c40d3",
   "metadata": {},
   "source": [
    "## 8) Tips & Best Practices\n",
    "- Keep `preprocess-id` / `inference-id` consistent across Pre/Infer/Post.\n",
    "- Use JSON files to make experiments reproducible.\n",
    "- Ensure your postprocess matches **tensor layout** and **scales**.\n",
    "- For remote sessions, prefer `autovideosink` or save to filesink during development.\n",
    "- Add `dxrate throttle=true` after `dxinfer` if you need to reduce NPU load in low-FPS pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
