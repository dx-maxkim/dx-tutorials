{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528ffbf3-26f1-4b0b-b49e-651397413a51",
   "metadata": {},
   "source": [
    "# DEEPX Tutorial 02 - Usage of DX_APP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d745a2c-590f-466c-8d99-dac51463d1a7",
   "metadata": {},
   "source": [
    "In this second tutorial, we will introduce DX_APP and learn how to utilize a converted DXNN model in an AI application. Additionally, we will cover how to use a USB webcam as an input source.\n",
    "\n",
    "This tutorial is based on dx-all-suite v2.0.0, released in September 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c593151-97c1-49c9-ac7b-d9149c7e58ba",
   "metadata": {},
   "source": [
    "## What is DX_APP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8fc6e5-dd5e-4014-a9bd-1aacde11dea1",
   "metadata": {},
   "source": [
    "**DX-APP** is a sample application that demonstrates how to run compiled models on actual DEEPX NPU\n",
    "using DX-RT. It includes ready-to-use code for common vision tasks such as object detection, face\n",
    "recognition, and image classification. DX-APP helps developers quickly set up the runtime environment\n",
    "and serves as a template for building and customizing their own AI applications.\n",
    "\n",
    "For more details, download DX_APP User Guide from ðŸ‘‰ [here](https://developer.deepx.ai/?files=MjUxOA==)!\n",
    "\n",
    "Let's see the file structure of DX_APP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae84aa2-63e1-4852-a0f7-c421f4d5157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dx-all-suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874e805-7b93-4b69-a82e-9f5c60e2788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 1 dx-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6631c-caa4-4c4f-b218-d21a0d42dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tree -L 1 dx-runtime/dx_app\n",
    "!tree -L 1 dx-runtime/dx_app/bin\n",
    "!tree -L 1 dx-runtime/dx_app/demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec96cc-5fe7-4a93-a39e-709db97d0465",
   "metadata": {},
   "source": [
    "**DX-APP** demos are optimized to showcase pre-compiled models on DEEPX NPUs with minimal setup.\n",
    "Each demo represents a common AI task and can be executed using images, videos, or live camera\n",
    "input.\n",
    "\n",
    "**Classification**\n",
    "- Executes classification models with image inputs (e.g., 224x224 ).\n",
    "- Outputs the Top-1 predicted class.\n",
    "- Example: example/run_classifier/imagenet_example.json\n",
    "\n",
    "**Object Detection**\n",
    "- For image input, outputs result.jpg and prints detected objects to the terminal.\n",
    "- For video input, displays bounding boxes on the output video.\n",
    "\n",
    "**Pose Estimation**\n",
    "- Detects people and estimates keypoints (joints) using image, video, or camera input.\n",
    "- The output includes both bounding boxes and joint coordinates rendered on screen.\n",
    "\n",
    "**Segmentation**\n",
    "- For image input, saves results to result.jpg and prints info to the terminal.\n",
    "- For video input, displays output with both detection boxes and segmentation masks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1addf3af-3464-4c65-bd6b-8c9bce945acc",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abf2e7-8ca9-42bc-81fd-2af1cb482a46",
   "metadata": {},
   "source": [
    "1. Move to `dx_app` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6584369-c62a-4604-8021-47e3e42d8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dx-runtime/dx_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf26c3-cd85-484c-bc4c-ef1a53f3b54a",
   "metadata": {},
   "source": [
    "2. Download required models and sample videos by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39177926-c29f-4701-9af1-a2f80525bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assets (models + videos) are downloaded and placed in the assets/ directory.\n",
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feedff76-7e3e-4407-8fd4-45ce6f44bafc",
   "metadata": {},
   "source": [
    "3. Verify that both models and videos are downloaded as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43627e-0705-4759-b60d-e40746d174cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI models converted to DXNN format\n",
    "!tree assets/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3b1d9-3c92-42d8-98b8-ad2018fc8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video files for demo inputs\n",
    "!tree assets/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48695b-d00c-47cc-9129-fbf41b63af73",
   "metadata": {},
   "source": [
    "## USB Webcam Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4e9b4-602c-4a35-8b4c-b54986382017",
   "metadata": {},
   "source": [
    "This hands-on notebook shows how to:\n",
    "- Discover USB webcams and inspect capabilities with **V4L2** (`v4l2-ctl`).\n",
    "- Configure formats (e.g., **MJPEG** or **YUYV**), resolution, FPS, and camera controls (exposure, focus, WB).\n",
    "- Capture images and video with **OpenCV** (both windowed & headless modes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e232d1-b618-4f7f-a80c-45c759ad0f88",
   "metadata": {},
   "source": [
    "### 0. Prerequisites (run once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b75ed-6d72-4146-9f4e-384c72e0da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y v4l-utils\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c24517-d7da-43fc-bbfd-11cc69ef4997",
   "metadata": {},
   "source": [
    "### 1. Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63484d94-0f23-4202-88a7-13b8ff462c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, subprocess, shutil, os, time, re, json, glob, pathlib\n",
    "import cv2\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "\n",
    "# Check v4l2-ctl availability\n",
    "v4l2_path = shutil.which(\"v4l2-ctl\")\n",
    "print(\"v4l2-ctl:\", v4l2_path if v4l2_path else \"NOT FOUND - please `sudo apt install v4l-utils`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fa430-61df-4e86-98ff-4f30b9372553",
   "metadata": {},
   "source": [
    "### 2. Discover Video Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f000c6-8760-4033-9540-92bf2ffb57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List /dev/video* nodes\n",
    "video_nodes = sorted(glob.glob(\"/dev/video*\"))\n",
    "print(\"Detected video nodes:\", video_nodes)\n",
    "\n",
    "# v4l2-ctl --list-devices gives a nice mapping (device -> /dev/videoX)\n",
    "if v4l2_path:\n",
    "    print(\"\\n== v4l2-ctl --list-devices ==\")\n",
    "    print(subprocess.run([\"v4l2-ctl\", \"--list-devices\"], capture_output=True, text=True).stdout)\n",
    "else:\n",
    "    print(\"v4l2-ctl not available; skipping device listing via v4l2-ctl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b2c49-6dbc-46f5-80f0-31cba4b210ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /dev/video*\n",
    "#!v4l2-ctl --list-devices\n",
    "#!cat /sys/class/video4linux/video*/name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173bfc3-123a-4b42-9e7b-e56c6eb2a2c0",
   "metadata": {},
   "source": [
    "### 3. Choose Your Webcam Device\n",
    "Set `DEVICE` to the `/dev/videoX` node of your webcam. If you're unsure, pick the first one that shows UVC capabilities in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141687f-b71d-41c1-8031-674c44b4a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your webcam node if needed\n",
    "DEVICE = \"/dev/video0\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a857d-f0d7-4e2b-b1e9-13fbf7fe1a36",
   "metadata": {},
   "source": [
    "### 4. Inspect Capabilities, Formats, and Frame Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d172a0-6509-48fb-8acd-5a854c6eeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DEVICE):\n",
    "    raise FileNotFoundError(f\"{DEVICE} not found. Update DEVICE to a valid /dev/videoX.\")\n",
    "\n",
    "if v4l2_path:\n",
    "    print(\"== v4l2-ctl --device --all ==\")\n",
    "    print(subprocess.run([\"v4l2-ctl\", f\"--device={DEVICE}\", \"--all\"], capture_output=True, text=True).stdout)\n",
    "\n",
    "    print(\"\\n== v4l2-ctl --device --list-formats-ext ==\")\n",
    "    print(subprocess.run([\"v4l2-ctl\", f\"--device={DEVICE}\", \"--list-formats-ext\"], capture_output=True, text=True).stdout)\n",
    "else:\n",
    "    print(\"v4l2-ctl not available; cannot show capabilities/formats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17893b-cf8c-4d59-a2a5-e6cc0a971add",
   "metadata": {},
   "outputs": [],
   "source": [
    "!v4l2-ctl --device {DEVICE} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fea3a-7fe8-4e72-aeae-3aeca90f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!v4l2-ctl --device {DEVICE} --list-formats-ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc7cce-2c6a-4969-a2f5-5116d7c99854",
   "metadata": {},
   "source": [
    "### 5. (Optional) Configure Format & FPS via V4L2\n",
    "\n",
    "Two common pixel formats:\n",
    "- **MJPG** (Motion JPEG): lower USB bandwidth, lighter CPU decode than raw â†’ often best for 1080p+ over USB.\n",
    "- **YUYV** (YUYV 4:2:2): raw frames, higher bandwidth but low latency and no compression artifacts.\n",
    "\n",
    "> We'll try setting **1920x1080 @ 30fps** with **MJPG**. Adjust if unsupported by your camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83cebb-72ab-4185-a17b-75a004a9ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFERRED_WIDTH, PREFERRED_HEIGHT, PREFERRED_FPS = 1920, 1080, 30\n",
    "PREFERRED_FOURCC = \"MJPG\"  # or \"YUYV\"\n",
    "\n",
    "if v4l2_path:\n",
    "    print(\"Setting format via v4l2-ctl ...\")\n",
    "    cmds = [\n",
    "        [\"v4l2-ctl\", f\"--device={DEVICE}\", f\"--set-fmt-video=width={PREFERRED_WIDTH},height={PREFERRED_HEIGHT},pixelformat={PREFERRED_FOURCC}\"],\n",
    "        [\"v4l2-ctl\", f\"--device={DEVICE}\", f\"--set-parm={PREFERRED_FPS}\"]\n",
    "    ]\n",
    "    for c in cmds:\n",
    "        res = subprocess.run(c, capture_output=True, text=True)\n",
    "        print(\"$\", \" \".join(c))\n",
    "        if res.stderr.strip():\n",
    "            print(\"stderr:\", res.stderr.strip())\n",
    "        if res.stdout.strip():\n",
    "            print(res.stdout.strip())\n",
    "else:\n",
    "    print(\"v4l2-ctl not available; skip format set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc37e5-92a6-4dd2-92e9-75d623c880e9",
   "metadata": {},
   "source": [
    "### 6. OpenCV Capture Basics\n",
    "\n",
    "We'll show two patterns:\n",
    "\n",
    "- **Headless (Notebook)**: display a few frames inline (no GUI windows).\n",
    "- **Windowed (Desktop)**: show a live window. Use this on a local desktop with a display server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cca55-f3cd-486c-b373-30ae3ae7a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_capture(dev=\"/dev/video0\", width=1280, height=720, fps=30, fourcc=\"MJPG\"):\n",
    "    cap = cv2.VideoCapture(dev, cv2.CAP_V4L2)  # prefer V4L2 backend on Linux\n",
    "    if fourcc:\n",
    "        # set FOURCC before size/fps for reliability\n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*fourcc))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "    # Some drivers report after opening; query back\n",
    "    actual = {\n",
    "        \"fourcc\": int(cap.get(cv2.CAP_PROP_FOURCC)),\n",
    "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n",
    "        \"backend\": int(cap.get(cv2.CAP_PROP_BACKEND))\n",
    "    }\n",
    "    return cap, actual\n",
    "\n",
    "cap, actual = open_capture(DEVICE, PREFERRED_WIDTH, PREFERRED_HEIGHT, PREFERRED_FPS, PREFERRED_FOURCC)\n",
    "print(\"Actual settings:\", actual)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Failed to open the camera. Check permissions and device node.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b1803-5541-4c67-80b1-564f52c2e2bb",
   "metadata": {},
   "source": [
    "#### 6.1 Headless Preview (Inline Frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2f72e-af4a-42ee-98d7-80fdabaa7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Capture 2 snapshots\n",
    "n_frames = 2\n",
    "imgs = []\n",
    "for i in range(n_frames):\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        print(\"Failed to read frame\")\n",
    "        break\n",
    "    # Optional: convert color if needed (OpenCV default is BGR)\n",
    "    # display inline\n",
    "    _, buf = cv2.imencode(\".jpg\", frame)\n",
    "    display(Markdown(f\"**Frame {i+1}**\"))\n",
    "    display(widgets.Image(value=buf.tobytes(), format='jpg', width=512))\n",
    "\n",
    "# Keep cap open for subsequent cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1c34c-a956-4b43-b31f-54b4201f57b4",
   "metadata": {},
   "source": [
    "#### 6.2 Windowed Live View\n",
    "\n",
    "> Run this only on a local desktop with a display (won't work on headless servers). Press **q** to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d058b-5c11-4f73-a6bd-81c33799c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "win = \"Live\"\n",
    "#cv2.namedWindow(win, cv2.WINDOW_NORMAL)\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    cv2.imshow(win, frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110dc6f-3e7a-4fba-800d-afc948d62f78",
   "metadata": {},
   "source": [
    "### 7. Handling YUYV (Raw 4:2:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9ff0c-6bb9-46f6-a23d-6825dfe2268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If MJPG is unavailable or you prefer raw frames, try YUYV.\n",
    "# We'll reopen with YUYV to demonstrate conversion.\n",
    "\n",
    "cap.release()\n",
    "cap, actual = open_capture(DEVICE, 640, 480, 30, \"YUYV\")\n",
    "print(\"Reopened with YUYV. Actual:\", actual)\n",
    "\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    print(\"Failed to read YUYV frame; your camera/driver may not support raw at this size/fps.\")\n",
    "else:\n",
    "    # Some backends already convert to BGR; if you get a single channel or strange shape, use cvtColor:\n",
    "    # Example: yuyv_bgr = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_YUY2)\n",
    "    # For demo, we will just show whatever we get:\n",
    "    _, buf = cv2.imencode(\".jpg\", frame)\n",
    "    display(Markdown(f\"**Frame {i+1}**\"))\n",
    "    display(widgets.Image(value=buf.tobytes(), format='jpg', width=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b336d-4a65-436a-8024-5094e7392138",
   "metadata": {},
   "source": [
    "## Run Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eba146-79f6-4d89-be95-92c65ff36636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls bin\n",
    "!./bin/classification -h\n",
    "#!./bin/classification -m assets/models/EfficientNetB0_4.dxnn -i sample/ILSVRC2012/1.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d198471e-c45b-4edd-9693-409719c4f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./bin/yolo -h\n",
    "!./bin/yolo -m assets/models/YOLOV5S_3.dxnn -i sample/face_sample.jpg -p 1\n",
    "#!eog result.jpg\n",
    "#!./bin/yolo -m assets/models/YOLOV5S_3.dxnn -v assets/videos/boat.mp4 -p 1\n",
    "#!./bin/yolo -m assets/models/YOLOV5S_3.dxnn -p 1 -c\n",
    "#!./bin/yolo -m assets/models/YOLOV5S_3.dxnn -p 1 -c --camera_path /dev/video0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbae31-1e12-47f7-9398-756583f57ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/yolo_multi -h\n",
    "#!cat example/yolo_multi/yolo_multi_demo.json\n",
    "#!./bin/yolo_multi -c example/yolo_multi/yolo_multi_demo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07558a9-8a49-4daa-bc91-e4d4a45a156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/pose -h\n",
    "#!./bin/pose -m assets/models/YOLOV5Pose640_1.dxnn -i sample/7.jpg -p 0\n",
    "#!./bin/pose -m assets/models/YOLOV5Pose640_1.dxnn -v assets/videos/dance-solo.mov -p 0\n",
    "#!./bin/pose -m assets/models/YOLOV5Pose640_1.dxnn -c -p 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27461eca-5e94-411e-828d-6bd585ec70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/segmentation -h\n",
    "#!./bin/segmentation -m assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -i sample/8.jpg\n",
    "#!./bin/segmentation -m assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -v assets/videos/blackbox-city-road.mp4\n",
    "#!./bin/segmentation -m assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f82e4-edcf-4e13-8500-84729fceed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./bin/od_segmentation -h\n",
    "#!./bin/od_segmentation -m0 assets/models/YoloV7.dxnn -p0 3 -m1 assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -i sample/8.jpg\n",
    "#!./bin/od_segmentation -m0 assets/models/YoloV7.dxnn -p0 3 -m1 assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -v assets/videos/blackbox-city-road2.mov\n",
    "!./bin/od_segmentation -m0 assets/models/YoloV7.dxnn -p0 3 -m1 assets/models/DeepLabV3PlusMobileNetV2_2.dxnn -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba9a91-b939-4473-ba69-6d0a3b38c206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
